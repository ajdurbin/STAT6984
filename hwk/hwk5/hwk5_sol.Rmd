---
title: "Homework 5"
subtitle: "Advanced Statistical Computing"
author: "Alexander Durbin"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
```

# Problem 1

## Part A

The contents of our `R` interface is as follows.

```{r, eval=FALSE}

# logliks
# R interface to C version
logliks <- function(Y, D, thetas, verb = 0){

    m <- ncol(Y)
    n <- nrow(Y)
    tlen <- length(thetas)
    out <- rep(0.01, tlen)
    
    ret <- .C("logliks_R",
              n = as.integer(n),
              m = as.integer(m), 
              Y = as.double(t(Y)),
              D = as.double(t(D)),
              thetas = as.double(thetas),
              tlen = as.integer(tlen),
              verb = as.integer(verb),
              out = as.double(out),
              DUP = FALSE)

     return(ret$out)

}

```

The following code is the matching `C` interface.

```{r, eval=FALSE}

/* C interface for logliks */

void logliks_R(int *n_in, int *m_in, double *Y_in, double *D_in,
    double *theta_in, int *tlen_in, int *verb_in, double *out){

    unsigned int i;
    unsigned int j;

    /* convert Y,D back to matrices */
    double **Y;
    double **D;
    D = (double **) malloc(sizeof(double*) * (*m_in));
    D[0] = D_in;
    for(i=1; i<*m_in; i++) D[i] = D[i - 1] + *m_in;
    Y = (double **) malloc(sizeof(double*) * (*n_in));
    Y[0] = Y_in;
    for(j=1; j<*n_in; j++) Y[j] = Y[j - 1] + *m_in;

    /* call logliks */
    logliks(*n_in, *m_in, Y, D, theta_in, *tlen_in, *verb_in, out);

    /* free memory back */
    free(D);
    free(Y);

}

```

## Part B

We extend the `C` version to use `OpenMP` parallelization in the following code, where we have two definitions of `loglik` depending on if the `OpenMP` flags were set during compilation.

```{r, eval=FALSE}

#ifdef _OPENMP

/*
 * loglik:
 *
 * calculates log likelihood for a multivariate normal distribution over 
 * a vector of theta values of length tlen used to define the covariance
 * structure; if D is m x m, then Y should be n x m.
 */

void logliks(int n, int m, double **Y, double **D, double *theta, 
	int tlen, int verb, double *llik)
{
  
#pragma omp parallel
{
  
  int me, nth;
  me = omp_get_thread_num();
  nth = omp_get_num_threads();
  
  double **K, **Ki;
  double *KiY;
  int i, j, t;
  double ldet, qf;
  
  /* create space */
  K = new_matrix(m, m);
  Ki = new_matrix(m, m);
  KiY = (double*) malloc(sizeof(double) *m);
  
  /* loop over thetas */
  for(t=me; t<tlen; t+=nth) {
    
    /* build covariance matrix */
    for(i=0; i<m; i++) {
      K[i][i] = 1.0 + SDEPS;
      for(j=i+1; j<m; j++)
        K[i][j] = K[j][i] = exp(0.0-D[i][j]/theta[t]);
    }
    
    /* calculate inverse and determinant*/
    ldet = invdet(m, K, Ki);
    
    /* initialize log likelihood calculation */
    llik[t] =  0.0 - n*(m*M_LN_SQRT_2PI + 0.5*ldet);
    
    /* calculate quadratic form */
    qf = 0.0;
    //#pragma omp parallel for private(i)
    for(i=0; i<n; i++) {
      dsymv(&upper,&m,&d_one,*Ki,&m,Y[i],&i_one,&d_zero,KiY,&i_one);
      qf += ddot(&m,KiY,&i_one,Y[i],&i_one);
    }
    
    /* finish log likelihood calculation */
    llik[t] -= 0.5*qf;
    
    /* progress meter */
    if(verb > 0 && (t+1) % verb == 0) 
      printf("t=%d, ll=%g\n", t+1, llik[t]);
    
  }
  
  /* clean up */
  delete_matrix(K);
  delete_matrix(Ki);
  free(KiY);
  
}
	
    //test
    printf("\nparallel\n");

}

#else

/*
 * loglik:
 *
 * calculates log likelihood for a multivariate normal distribution over 
 * a vector of theta values of length tlen used to define the covariance
 * structure; if D is m x m, then Y should be n x m.
 */

void logliks(int n, int m, double **Y, double **D, double *theta, 
	int tlen, int verb, double *llik)
{
	double **K, **Ki;
	double *KiY;
	int i, j, t;
	double ldet, qf;

	/* create space */
	K = new_matrix(m, m);
	Ki = new_matrix(m, m);
	KiY = (double*) malloc(sizeof(double) *m);

	/* loop over thetas */
	for(t=0; t<tlen; t++) {

		/* build covariance matrix */
		for(i=0; i<m; i++) {
			K[i][i] = 1.0 + SDEPS;
			for(j=i+1; j<m; j++)
				K[i][j] = K[j][i] = exp(0.0-D[i][j]/theta[t]);
		}

		/* calculate inverse and determinant*/
		ldet = invdet(m, K, Ki);

		/* initialize log likelihood calculation */
		llik[t] =  0.0 - n*(m*M_LN_SQRT_2PI + 0.5*ldet);

		/* calculate quadratic form */
		qf = 0.0;
		for(i=0; i<n; i++) {
			dsymv(&upper,&m,&d_one,*Ki,&m,Y[i],&i_one,&d_zero,KiY,&i_one);
			qf += ddot(&m,KiY,&i_one,Y[i],&i_one);
		}

		/* finish log likelihood calculation */
		llik[t] -= 0.5*qf;

		/* progress meter */
		if(verb > 0 && (t+1) % verb == 0) 
			printf("t=%d, ll=%g\n", t+1, llik[t]);
        
	}

	/* clean up */
	delete_matrix(K);
	delete_matrix(Ki);
	free(KiY);

    //test
    printf("\nnot parallel\n");
}

#endif

```

## Part C and Part D

For this problem, we ran the likelihood implimentations at different times and saved the results in `.RData` files for later plotting. Both `R` versions and the non-parallel `C` version were run on a local machine at the same time. The parallel `C` version was run on a local machine after a re-compilation with the appropriate `OpenMP` flags.

```{r}

rm(list = ls())
load("/home/alex/asc_durbin/hwk/hwk5/mvnllik/R/data.RData")
load("/home/alex/asc_durbin/hwk/hwk5/mvnllik/R/local_serial.RData")
load("/home/alex/asc_durbin/hwk/hwk5/mvnllik/R/local_omp.RData")

```

Timing comparisons are as follows. Note that the `OpenMP` `C` implimentation used 4 cores on a local machine.

```{r}

ll_1_time
ll_2_time
ll_c_serial_time
ll_c_omp_time

```

We see that both `C` implimentations are the fastest, with the `OpenMP` implimentation four times faster than without. `loglik2` is twice as slow as `loglik` and `logliks`.

```{r}

ggplot() + 
  geom_point(mapping = aes(x = thetas, y = ll_1)) +
  xlab("Theta") +
  ylab("Likelihood") +
  ggtitle("loglik")
paste0("Maximum Likelihood Estimate Of Theta: ", thetas[which.max(ll_1)])

ggplot() + 
  geom_point(mapping = aes(x = thetas, y = ll_2)) +
  xlab("Theta") +
  ylab("Likelihood") +
  ggtitle("loglik2")
paste0("Maximum Likelihood Estimate Of Theta: ", thetas[which.max(ll_2)])

ggplot() + 
  geom_point(mapping = aes(x = thetas, y = ll_c_serial)) +
  xlab("Theta") +
  ylab("Likelihood") +
  ggtitle("logliks")
paste0("Maximum Likelihood Estimate Of Theta: ", thetas[which.max(ll_c_serial)])

ggplot() + 
  geom_point(mapping = aes(x = thetas, y = ll_c_omp)) +
  xlab("Theta") +
  ylab("Likelihood") +
  ggtitle("logliks with omp")
paste0("Maximum Likelihood Estimate Of Theta: ", thetas[which.max(ll_c_omp)])

```

We see that all four implimentations have the same likelihood curve and achieve the same maximum, thus the implimentations are equivalent.

## Part E

Similar to Part C and Part D, the different implimentations were run at different times with results saved similarly. However, for using the `MKL` libraries, this code was run on Virginia Tech's ARC machines.

```{r}

load("/home/alex/asc_durbin/hwk/hwk5/mvnllik/R/remote_serial.RData")
load("/home/alex/asc_durbin/hwk/hwk5/mvnllik/R/remote_omp.RData")

```

The runtimes are as follows. Note during runtime that all 32 cores were used on the ARC machine.

```{r}

ll_1_time_mkl
ll_2_time_mkl
ll_c_serial_time_mkl
ll_c_omp_time_mkl

```

We see vastly improved times in three of the four implimentations using the accelerated libraries. Surprisingly, `loglik2` performs slower on ARC than running on local. Also of note is that the serial `loglik` performs faster than the `OpenMP` version. 

# Problem 2

Again, similar to #1, code was run locally and remotely with intermediate saving of objects.

Our `R` and `C` versions are as follows, with a conditional function definition based on compile-time flags for `OpenMP`.

```{r, eval = FALSE}

bootols <- function(X, y, B=199, icept=TRUE, inv=FALSE)
{
	if(icept) X <- cbind(1, X)	
	m <- ncol(X)
	n <- nrow(X)
	if(n != length(y)) stop("dimension mismatch")

	ret <- .C("bootols_R",
	  		  X = as.double(t(X)),
	  		  y = as.double(y),
	  		  n = as.integer(n),
	  		  m = as.integer(m),
	  		  B = as.integer(B),
	  		  inv = as.integer(inv),
	  		  beta.hat = double(m*B),
	  		  DUP = FALSE)

	## must be careful to return a transposed beta.hat matrix
	return(matrix(ret$beta.hat, nrow=B, byrow=TRUE))
}

```

```{r, eval=FALSE}

/*
 * bootols_R:
 *
 * bootstrap R interface to ols()
 */

void bootols_R(double *X_in, double *Y_in, int *n_in, int *m_in, 
	           int *B_in, int *inv_in, double *beta_hat_out)
{
	int i;
	double **X, **beta_hat;

   	/* change a vector representation of X into a array one */
   	X = (double **) malloc(sizeof(double*) * (*n_in));
   	X[0] = X_in;
   	for(i=1; i<*n_in; i++) X[i] = X[i-1] + *m_in;

   	/* change a vector representation of beta_hat_out into a array one */
   	beta_hat = (double **) malloc(sizeof(double*) * (*B_in));
   	beta_hat[0] = beta_hat_out;
   	for(i=1; i<*B_in; i++) beta_hat[i] = beta_hat[i-1] + *m_in;

   	/* for R's RNG */
   	GetRNGstate();

   	/* call the C-side subroutine */
   	bootols(X, Y_in, *n_in, *m_in, *B_in, *inv_in, beta_hat);

   	/* for R's RNG */
   	PutRNGstate();

   	/* clean up */
   	free(X);
   	free(beta_hat);
}


#ifdef _OPENMP

/*
 * bootols:
 *
 * Bootstrap OLS subroutine, for B bootstrap samples of beta_hat
 */

void bootols(double **X, double *Y, int n, int m, int B, int inv, double **beta_hat) 
{
  
  #pragma omp parallel
  {
  
    int me, nth;
    me = omp_get_thread_num();
    nth = omp_get_num_threads();

    int b, i, j, bindex;
    double **Xb, **XtX, **XtXi;
    double *XtY, *Yb;
  
    /* temporary space for ols */
    XtX = new_matrix(m, m); 
    if(inv) {
      XtY = (double*) malloc(sizeof(double) * m);
      XtXi = new_matrix(m, m);
    } else { XtY = NULL; XtXi = NULL; }
    Xb = new_matrix(n, m);
    Yb = (double*) malloc(sizeof(double) * n);	
    
    /* loop over bootstrap rounds */
    for(b=me; b<B; b+=nth) {/* fill Xb and Yb */
      for(i=0; i<n; i++) {
        bindex = floor(n * unif_rand()); /* Rs RNG */
        Yb[i] = Y[bindex];
        for(j=0; j<m; j++) Xb[i][j] = X[bindex][j];
      }
    
      /* call ols on Xb Yb */
      ols(Xb, Yb, n, m, XtY, XtX, XtXi, beta_hat[b]);
    }
    
    /* clean up */
    delete_matrix(Xb);
    free(Yb);
    delete_matrix(XtX);
    if(XtXi) delete_matrix(XtXi);
    if(XtY) free(XtY);
  
  }
	
}

#else

/*
 * bootols:
 *
 * Bootstrap OLS subroutine, for B bootstrap samples of beta_hat
 */

void bootols(double **X, double *Y, int n, int m, int B, int inv, double **beta_hat) 
{
  int b, i, j, bindex;
  double **Xb, **XtX, **XtXi;
  double *XtY, *Yb;
  
  /* temporary space for ols */
  XtX = new_matrix(m, m); 
  if(inv) {
    XtY = (double*) malloc(sizeof(double) * m);
    XtXi = new_matrix(m, m);
  } else { XtY = NULL; XtXi = NULL; }
  Xb = new_matrix(n, m);
  Yb = (double*) malloc(sizeof(double) * n);	
  
  /* loop over bootstrap rounds */
  for(b=0; b<B; b++) {/* fill Xb and Yb */
    for(i=0; i<n; i++) {
      bindex = floor(n * unif_rand()); /* Rs RNG */
      Yb[i] = Y[bindex];
      for(j=0; j<m; j++) Xb[i][j] = X[bindex][j];
    }
  
    /* call ols on Xb Yb */
    ols(Xb, Yb, n, m, XtY, XtX, XtXi, beta_hat[b]);
  }
  
  /* clean up */
  delete_matrix(Xb);
  free(Yb);
  delete_matrix(XtX);
  if(XtXi) delete_matrix(XtXi);
  if(XtY) free(XtY);
  
}

#endif

```

```{r}

rm(list = ls())
load("/home/alex/asc_durbin/hwk/hwk5/bootols/R/remote_serial.RData")
load("/home/alex/asc_durbin/hwk/hwk5/bootols/R/remote_omp.RData")
load("/home/alex/asc_durbin/hwk/hwk5/bootols/R/local_omp.RData")
load("/home/alex/asc_durbin/hwk/hwk5/bootols/R/local_serial.RData")

```

We next compare methods run locally and remotely using accelerated linear algebra libraries.

```{r, include=FALSE}

local_times <- data.frame(c(local_cinv_time[3], 
                      local_cinv_time_omp[3],
                      local_csolve_time[3],
                      local_csolve_time_omp[3],
                      local_rcp_time[3],
                      local_rlm_time[3],
                      local_rsolve_time[3],
                      local_rinv_time[3]),
                    row.names = c("C Inverse", "C Inverse Parallel", "C Solve", "C Solve Parallel", "R CP", "R LM", "R Solve", "R Inverse"))
colnames(local_times) <- c("time")

remote_times <- data.frame(c(remote_cinv_time[3], 
                        remote_cinv_time_omp[3],
                        remote_csolve_time[3],
                        remote_csolve_time_omp[3],
                        remote_rcp_time[3],
                        remote_rlm_time[3],
                        remote_rsolve_time[3],
                        remote_rinv_time[3]),
                      row.names = c("C Inverse", "C Inverse Parallel", "C Solve", "C Solve Parallel", "R CP", "R LM", "R Solve", "R Inverse"))
colnames(remote_times) <- c("time")

```

```{r}

knitr::kable(local_times, caption = "Local Runs Without MKL")

```

Similar to what we saw in class, the `R` versions are very slow depending on what solver you use. The parallelized `C` versions perform almost twice as fast as their serial counterparts. 

```{r}

knitr::kable(remote_times, caption = "Remote Runs With MKL")

```

Using the accelerated linear algebra libraries, we see massive performance gains in all methods besides the native `R` `lm()` implimentation. Both `OpenMP` parallelized `C` versions are the fastest implimentations again and have comparable times. They are closely followed by their non-parallel counterparts. The other `R` versions do experience massive performance gains as well. 

# Problem 3

The contents of `swap.cpp` is as follows. Note that we can easily modify the types of `v` and `tmp` accordingly.

```{r, eval=FALSE}

#include <Rcpp.h>
using namespace Rcpp;

// [[Rcpp::export]]
void swap_Rcpp(IntegerVector& v, int i, int j){
  
  int tmp;
  tmp = v[i];
  v[i] = v[j];
  v[j] = tmp;
  
}

```

`swap.eval` is the following code.

```{r}

rm(list = ls())
swap.eval <- function()
{
  e <- quote({tmp <- v[i]; v[i] <- v[j]; v[j] <- tmp})
  eval(e, envir=parent.frame())
}

```

We compare the previous implimentations as follows. Recall that indicies start at 0 in `C++`.

```{r}

Rcpp::sourceCpp("/home/alex/asc_durbin/hwk/hwk5/rcpp/swap/swap.cpp")

v <- 1:1000000000

print(v[1])
print(v[2])

system.time(swap_Rcpp(v, 0, 1))

print(v[1])
print(v[2])

system.time(swap_Rcpp(v, 0, 1))

print(v[1])
print(v[2])

system.time(swap_Rcpp(v, 0, 1))

print(v[1])
print(v[2])

i <- 1
j <- 2

print(v[1])
print(v[2])

system.time(swap.eval())

print(v[1])
print(v[2])

system.time(swap.eval())

print(v[1])
print(v[2])

system.time(swap.eval())

print(v[1])
print(v[2])

```

`swap_Rcpp` is initially faster than `swap.eval`, but for the latter two runs, they are comparable. The first run of `swap.eval` is very slow before being instantaneous. We aren't sure what to attribute this result to.

# Problem 4

Again, we run code intermediately and across machines for good comparisons. The contents of `loglik.cpp` are as follows. We have both serial and parallel versions.

```{r, eval=FALSE}

#include <RcppArmadillo.h>
using namespace Rcpp;

// [[Rcpp::depends(RcppArmadillo)]]
// [[Rcpp::export]]
arma::vec logliks_Rcpp(arma::mat Y, arma::mat D, arma::vec thetas,
    double precision){
    int tlen = thetas.n_elem;
    int m = D.n_rows;
    int n = Y.n_rows;
    arma::vec likes(tlen);
    for(int i = 0; i < tlen; i++){
      double theta = thetas(i);
      arma::mat Sigma = exp(-D/theta);
      arma::mat Schol = arma::chol(Sigma);
      double ldet = 2 * arma::accu(arma::log(Schol.diag()));
      arma::mat Si = arma::inv_sympd(Sigma);
      double ll = -0.5 * n * (m * log(2 * arma::datum::pi) + ldet); 
      for(int j = 0; j < n; j++){
          ll -= arma::as_scalar(0.5 * Y.row(j) * Si * arma::trans(Y.row(j)));
      }
      likes(i) = ll;
    }  
    return(likes);
}


// [[Rcpp::plugins(openmp)]]
// [[Rcpp::depends(RcppArmadillo)]]
// [[Rcpp::export]]
arma::vec logliks_Rcpp_omp(arma::mat Y, arma::mat D, arma::vec thetas,
    double precision, int cores){
    int tlen = thetas.n_elem;
    int m = D.n_rows;
    int n = Y.n_rows;
    arma::vec likes(tlen);
    omp_set_num_threads(cores);
    #pragma omp parallel for schedule(static)
    for(int i = 0; i < tlen; i++){
        double theta = thetas(i);
        arma::mat Sigma = exp(-D/theta);
        arma::mat Schol = arma::chol(Sigma);
        double ldet = 2 * arma::accu(arma::log(Schol.diag()));
        arma::mat Si = arma::inv_sympd(Sigma);
        double ll = -0.5 * n * (m * log(2 * arma::datum::pi) + ldet); 
        for(int j = 0; j < n; j++){
            ll -= arma::as_scalar(0.5 * Y.row(j) * Si * arma::trans(Y.row(j)));
        }
        likes(i) = ll;
    }     
    return(likes);
}

```

```{r}

rm(list = ls())
load("/home/alex/asc_durbin/hwk/hwk5/mvnllik/R/data.RData")
load("/home/alex/asc_durbin/hwk/hwk5/mvnllik/R/local_serial.RData")
load("/home/alex/asc_durbin/hwk/hwk5/mvnllik/R/local_omp.RData")
load("/home/alex/asc_durbin/hwk/hwk5/mvnllik/R/remote_serial.RData")
load("/home/alex/asc_durbin/hwk/hwk5/mvnllik/R/remote_omp.RData")
load("/home/alex/asc_durbin/hwk/hwk5/rcpp/mvnllik/local_rcpp.RData")
load("/home/alex/asc_durbin/hwk/hwk5/rcpp/mvnllik/remote_rcpp.RData")

```

```{r}

ggplot() + 
  geom_point(mapping = aes(x = thetas, y = ll_rcpp_serial)) +
  xlab("Theta") +
  ylab("Likelihood") +
  ggtitle("RCpp Serial")
paste0("Maximum Likelihood Estimate Of Theta: ", thetas[which.max(ll_rcpp_serial)])

ggplot() + 
  geom_point(mapping = aes(x = thetas, y = ll_rcpp_omp)) +
  xlab("Theta") +
  ylab("Likelihood") +
  ggtitle("RCpp OMP")
paste0("Maximum Likelihood Estimate Of Theta: ", thetas[which.max(ll_rcpp_omp)])

```

Graphing our local machine serial and parallel `RCpp` implimentations, we see that they have the same likelihood curve as our previous `R` and `C` versions. 

```{r, include=FALSE}

local_times <- data.frame(c(ll_1_time[3], 
                      ll_2_time[3],
                      ll_c_omp_time[3],
                      ll_c_serial_time[3],
                      ll_rcpp_omp_time[3],
                      ll_rcpp_serial_time[3]),
                    row.names = c("loglik", "loglik2", "C OMP", "C Serial", "RCpp OMP", "RCpp Serial"))
colnames(local_times) <- c("time")

remote_times <- data.frame(c(ll_1_time_mkl[3], 
                             ll_2_time_mkl[3],
                             ll_c_omp_time_mkl[3],
                             ll_c_serial_time_mkl[3],
                             ll_rcpp_omp_time_mkl[3],
                             ll_rcpp_serial_time_mkl[3]),
                      row.names = c("loglik", "loglik2", "C OMP", "C Serial", "RCpp OMP", "RCpp Serial"))
colnames(remote_times) <- c("time")

```

```{r}

knitr::kable(local_times, caption = "Local Runs Without MKL")

```

We see that the `RCpp` versions are twice about twice as slow as the pure `C` versions. Additionally the serial `RCpp` is slower than `R`'s `loglik`, which is suprising. We think that the choice of inverse used in the `RCpp` version may have affect the timings. 

```{r}

knitr::kable(remote_times, caption = "Remote Runs With MKL")

```

Looking at the remote runs with accelerated linear algebra libraries, we see an improvement in all timings aside from `R`'s `lm()` that we noted above. We also see that the serial `C` version is slightly faster than the parallel version. Furthermore, we see that the parallel `C` and `RCpp` versions are comparable, unlike our local machine runs. Also, the serial `RCpp` version is again beaten by `R`'s `loglik`. We think that for writing pure `C` code and running on a machine with accelerated linear algebra libraries do not benefit greatly from being written for parallel execution.
