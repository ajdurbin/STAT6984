---
title: "Homework 4 Solutions"
subtitle: "Advanced Statistical Computing"
author: "Alexander Durbin"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(boot)
```

# Problem 1
## Part A

The following code contains all function declarations.

```{r}

powers1 <- function(x, dg)
{
  pw <- matrix(x, nrow=length(x))
  prod <- x ## current product
  for(i in 2:dg) {
    prod <- prod * x
    pw <- cbind(pw, prod)
  }
  return(pw)
}

powers2 <- function(x, dg)
{
  pw <- matrix(nrow=length(x), ncol=dg)
  prod <- x ## current product
  pw[,1] <- prod
  for(i in 2:dg) {
    prod <- prod * x
    pw[,i] <- prod
  }
}

powers3 <- function(x, dg) outer(x, 1:dg,"^")

powers4 <- function(x, dg) 
{
  repx <- matrix(rep(x, dg), nrow=length(x))
  return(t(apply(repx, 1, cumprod)))
}

x <- runif(10000000)
dg <- 16

```

`powers3` provides the shortest syntax for computing the powers of a vector. It uses the `outer` function in `R` with the exponentiation operator. It will loop through all of the values in `dg` and compute `x` raised to that power. There is certainly some form of copying involved here.

`powers4` tries to rectify the copying issue by preallocating storage in `repx` with copies of `x` itself. It then uses the `cumprod` function inside the `apply` statement to perform the exponentiation. The hope is that the `apply` statement can make up speed over using a `for` loop. However, we have shown in class that the `apply` family of functions can be slow in some cases and beaten by regualr `for` loops. This operation could be sped up by using the `parallel` package and a `parapply` statement instead.

Both of these functions elect for cleaner syntax than the original functions.

## Part B

The following code provides the runtimes for each of the above functions twice.

```{r}

system.time(powers1(x, dg))
system.time(powers1(x, dg))

system.time(powers2(x, dg))
system.time(powers2(x, dg))

system.time(powers3(x, dg))
system.time(powers3(x, dg))

system.time(powers4(x, dg))
system.time(powers4(x, dg))

```

We see that `powers2` is by far the fastest. `powers1` is about twice as slow as `powers1`. `powers3` is about four times slower than `powers1` and `powers4` is by far the slowest implimentation.

## Part C

The next code chunks will profile `powers3` and `powers4`. After each run, we remove `tmp` and use the `gc()` command to return memory back to the operating system in order to better identify CPU and memory usage differences. When knitting this document, profile statements have more noise from the `knitr` processes. To remove this noise, we run the following chunks in the console with no applications besides RStudio and a terminal open.

The following code profiles `powers3`.

```{r, warning=FALSE}

Rprof(memory.profiling = TRUE)
tmp <- powers3(x, dg)
Rprof(NULL)
summaryRprof()
format(object.size(tmp), units = 'Gb')
rm(tmp)
gc()

```

We see that almost all of the computational effort is spent inside the `outer` function. Also checking `htop` during execution of the above commands in the console, we see CPU usage spike to 100% as well as more than double memory usage from 2.33 Gb to 5.37 Gb, though some of this is certainly due to the returned object size. There are no specific subroutines or functions within `outer` that we can attribute this slow runtime to.

The following code profiles `powers4`.

```{r}

Rprof(memory.profiling = TRUE)
tmp <- powers4(x, dg)
Rprof(NULL)
summaryRprof()
format(object.size(tmp), units = 'Gb')
rm(tmp)
gc()

```

Using `htop` during this runtime, we see that memory usage increase from 2.3Gb to over 9Gb. `powers4` is an extremely memory intensive process. CPU usage is also at 100% during execution. There are multiple subroutines within `powers4` that we can arttribute this bottleneck to. As suggest above, the `apply` statement is the most intensive process. Surprisingly, the transpose statement is also intensive. There are also several subroutines that are also computationally intensive, though they are subroutines of the above two statements. The `apply` statement includes the subroutines `FUN`, `aperm.default`, `array`, and `lengths`, of which `FUN` and `aperm.default` are most intensive. The `tranpose` statement includes `matrix`, `array`, and `lengths` subroutines. This operation can be sped up using the `parallel` package with a `parApply` statement, however this may not solve the memory issues.

# Problem 2

To accomodate other distributions, we need only change the sampling procedure. We use a simple function that takes two arguments, the distributions of both Annie and Sam. We include a couple safety check to ensure that the distributions are the same length.

```{r}

as_prob <- function(dista, dists){
  if(length(dista) != length(dists)){
    stop('Sample size must be the same for both Annie and Sam.')
  }
  
  S <- dista
  A <- dists
  # probability Annie arrives later than Sam
  prob <- mean(A < S)
  cat("\nThe probability Annie arrives after Sam is ", prob)
  #expected differences
  diff <- A - S
  cat("\nThe expected difference between arrival times is ", mean(abs(diff)), "\n")
}

as_prob(1:10, rnorm(10,10,1))
as_prob(runif(1000, 10, 11.5), runif(1000, 10, 12))
as_prob(rnorm(1000, 10.5, 1), rnorm(1000, 11, 1.5))
try({as_prob(1:9, 1:10)})

```

# Problem 3

The bootstrap linear regression example from class is the following code.

```{r}

## bootstrapped linear regression
n <- 200
X <- 1/cbind(rt(n, df=1), rt(n, df=1), rt(n,df=1))
beta <- c(1,2,3,0)
Y <- beta[1] + X %*% beta[-1] + rnorm(100, sd=3)
fit <- lm(Y~X)
coef(fit)  ## try/not in slides
summary(fit)$cov.unscaled

## now take the bootstrap samples
B <- 10000
beta.hat.boot <- matrix(NA, nrow=B, ncol=length(beta))
for(b in 1:B) {
  indices <- sample(1:nrow(X), nrow(X), replace=TRUE)
  beta.hat.boot[b,] <- coef(lm(Y[indices]~X[indices,]))
}


```

Our code using the `boot` library is as follows. We need to define a 'statistic' in the `boot` library in order to get the regression coefficients from the bootstrap samples.

```{r}

## 'statistic' for boot call
reg_coef <- function(data, indices){
  fit <- lm(Y ~ ., data = data[indices, ])
  return(coef(fit))
}

## boot call
df <- data.frame(Y = Y, X = X)
bs_reg <- boot(data = df, statistic = reg_coef, R = B)

```

We next compare the covariance matrices. 

```{r}

## from fit
summary(fit)$cov.unscaled
## manual boot samples
cov(beta.hat.boot)
## boot library samples
cov(bs_reg$t)

```

We take differences between the covariance matrices to better identify their differences.

```{r}

# truth vs manual
summary(fit)$cov.unscaled - cov(beta.hat.boot)
# truth vs library
summary(fit)$cov.unscaled - cov(bs_reg$t)
# manual vs library
cov(beta.hat.boot) - cov(bs_reg$t)

```

So that while the covarainces matrices are not exact between the truth, manual bootstrap, and library bootstrap, the differences are small.

We modify the plot statement used in class to get side-by-side histograms to better compare the manual versus library bootstrapping.

```{r}

## comparing marginals
par(mfrow=c(1,2))
for(i in 1:4) {
  m <- coef(fit)[i]
  s1 <- sqrt(cov(beta.hat.boot)[i,i])
  s2 <- sqrt(cov(bs_reg$t)[i,i])
  x1 <- m + seq(-4*s1, 4*s1, length=1000)
  x2 <- m + seq(-4*s2, 4*s2, length=1000)
  xlim1 <- range(c(x1, beta.hat.boot[,i]))
  xlim2 <- range(c(x2, bs_reg$t[,i]))
  hist(beta.hat.boot[,i], freq=FALSE, xlim=xlim1,
       xlab=i, main="manual", breaks=20)
  lines(x1, dnorm(x1, m, s1), col=2, lwd=2)
  hist(bs_reg$t[,i], freq=FALSE, xlim=xlim2,
       xlab=i, main="library", breaks=20)
  lines(x2, dnorm(x2, m, s2), col=2, lwd=2)
}

```

Comparing the marginal distributions of the coefficients, we see that the manual and library-based bootrap distributions are nearly identical to each other. However, the $\beta_1$ coefficients for both methods do not follow the theoretical distribution of the coefficient. This is due to the resampling procedure.

# Problem 4

We generate the data exactly as in class. We then obtain bootstrap samples before using `smooth.spline` with cross-validation to make predictions. We store all of the bootstrap predictions before taking the means and quantiles for plotting. For this code chunk we have to turn off warnings, as `smooth.spline` throws warnings for non-unique samples during cross-validation.

```{r, warning=FALSE}


## non-linear data
X <- seq(0,10,length=50)
Ytrue <- (sin(pi*X/5) + 0.2*cos(4*pi*X/5))
Y <- Ytrue + rnorm(length(Ytrue), sd=0.1)

## predictive locations
XX <- seq(0,10,length=199)

## bootstrap iterations
B <- 1000

## storage for predictions
sto <- matrix(NA, nrow = B, ncol = length(XX))

## bootstrap procedure
for(i in 1:B){
  indices <- sample(1:length(X), size = length(X), replace = TRUE)
  xboot <- X[indices]
  yboot <- Y[indices]
  fit <- smooth.spline(x = xboot, y = yboot, cv = TRUE)
  preds <- predict(fit, XX)
  sto[i, ] <- preds$y
}

## get means and quantiles
pred_mean <- apply(sto, 2, mean)
pred_low <- apply(sto, 2, function(col) quantile(col, probs = c(0.05)))
pred_high <- apply(sto, 2, function(col) quantile(col, probs = c(0.95)))

## plots
plot(X,Y, main = "Bootstrapped Spline With Cross-Validation")
lines(XX, pred_mean, col = "blue", type = "l", lwd = 2)
lines(XX, pred_low, col = "red", lty = 6, lwd = 1)
lines(XX, pred_high, col = "red", lty = 6, lwd = 1)

```

# Problem 5

The contents of `spam_mc.sh` are as follows.

```{r, eval=FALSE}

#!/bin/bash

# check if 0 or more than 1 arguments
if [[ $# -eq 0 ]];
then
    value=2
elif [[ $# -gt 1 ]];
then
    echo "TOO MANY ARGUMENTS"
    exit
fi

# if single argument, validate and update
if [[ $# -eq 1 ]];
then
    value=$1
    # check if an integer
    if [[ -n ${value//[0-9]/} ]];
    then
        echo "INVALID ARGUMENT"
        exit
    fi
fi

# check if greater than number of cores in machine
nprc=$(nproc)
if [[ $value -gt $nprc ]];
then
    echo "MORE CORES THAN AVAILABLE - USING 2 CORES"
    value=2
fi

# now call r scripts
for((i=1; i<=$value; i++))
do
    nohup R CMD BATCH "--args seed=$i reps=5" spam_mc.R spam_mc_$i.Rout &
done


```

For the following boxplots, we used the batch method of 32 repetitions and the bash script method across 4 cores of 8 repetitions each.

The following is the pairwise t-test results.

```{r, eval=FALSE}

        dfmean           tt
rf   0.9519670 8.777168e-21
fwdi 0.9329168 7.934943e-09
full 0.9235601 1.124757e-03
fwd  0.9202021 1.552431e-20
rp   0.8939144 8.608004e-09
fda  0.8866768 1.649384e-01
lda  0.8866659 2.290342e-26
qda  0.8298929 2.061578e-37
null 0.6059552           NA

```

![Spam bakeoff results.](spam.png)


# Problem 5

The contents of `spam_snow.sh` are as follows. We check the number of arguments within the bash script and then check the cores argument within `spam_snow.R`. For `spam_snow.R`, we use `clusterApply()` with the class version of `spam_mc.R` slightly modified as into a function. Note that function `unpack` was developed with Chris Grubb in this solution.

```{r, eval = FALSE}

#!/bin/bash

# check if 0, 1, or more than 1 argument
if [[ $# -eq 0 ]];
then 
    value=4
elif [[ $# -gt 1 ]];
then
    echo "TOO MANY ARGUMENTS, USING 4 CORES"
    value=4
else
    value=$1
fi

R CMD BATCH "--args cores=$value" spam_snow.R

```

